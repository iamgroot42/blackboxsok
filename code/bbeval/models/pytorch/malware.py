import torch as ch
import numpy as np
import os
from typing import List

from bbeval.config import MalwareModelConfig
from bbeval.models.pytorch.wrapper import PyTorchModelWrapper
from bbeval.datasets.malware.base import MalwareDatumWrapper

from secml.array import CArray
from secml_malware.models.malconv import MalConv
from secml_malware.models.c_classifier_end2end_malware import CClassifierEnd2EndMalware, End2EndModel
from secml_malware.models.c_classifier_ember import CClassifierEmber
from secml.ml import CClassifier
from secml_malware.models.c_classifier_sorel_net import CClassifierSorel
from secml_malware.attack.blackbox.c_wrapper_phi import CEnd2EndWrapperPhi, CEmberWrapperPhi, CSorelWrapperPhi, CWrapperPhi


class SecmlEnsemblPhi(CWrapperPhi):
    def __init__(self, models: List[PyTorchModelWrapper]):
        self.models = [model.get_phi_wrapper_class()(model.model) for model in models]
        self.classifier = SecmlEnsemble(models, for_phi=True)
        self.n_ensemble = len(models)
    
    def extract_features(self, x: CArray):
        # Assume all same for now, just return first one
        return self.models[0].extract_features(x)
        features = [model.extract_features(x) for model in self.models]
        return features


class SecmlEnsemble(CClassifier):
    def __init__(self, models: List[PyTorchModelWrapper], for_phi: bool = False):
        self.models = models
        self.n_ensemble = len(models)
        if not for_phi:
            embedding_sizes = [model.get_embedding_size() for model in self.models]
            max_input_lengths = [model.get_input_max_length() for model in self.models]
            is_shifting_values = [model.get_is_shifting_values() for model in self.models]
            embedding_value = [model.get_embedding_value() for model in self.models]
            assert np.unique(embedding_sizes).size == 1, "All aux models must have the same embedding size"
            assert np.unique(max_input_lengths).size == 1, "All aux models must have the same max input length"
            self.embedding_size = embedding_sizes[0]
            self.max_input_length = max_input_lengths[0]
            self.is_shifting_values = is_shifting_values[0]
            self.embedding_value = embedding_value[0]
    
    def predict(self, x, return_decision_function: bool = False):
        return self.models[0].model.predict(x, return_decision_function=return_decision_function)

    def get_embedding_value(self):
        return self.embedding_value
    
    def get_is_shifting_values(self):
        return self.is_shifting_values
    
    def get_input_max_length(self):
        return self.max_input_length

    def get_embedding_size(self):
        return self.embedding_size

    def _fit(self, x, y):
        # Placeholder function (for compatibility)
        raise NotImplementedError("Ensemble fitting not implemented")
    
    def embed(self, x, transpose: bool = True):
        # Assumes all models embed the same way (does not check)
        # TODO: Could check (but would be expensive)
        return self.models[0].embed(x, transpose=transpose)
    
    def embedding_predict(self, x):
        combined = ch.stack([model.embedding_predict(x) for model in self.models])
        combined = combined.mean(0)
        return combined

    def forward(self, x, caching: bool = True):
        combined = np.stack([model.forward(x, caching=caching).tondarray() for model in self.models])
        combined = CArray(combined.mean(0))
        return combined

    def pre_process_fn(self, X: List[MalwareDatumWrapper]):
        return [m.pre_process_fn(X) for m in self.models]

    def _forward(self, x):
        return ch.stack([m.forward(x) for m in self.models]).mean(0)

    def cuda(self):
        for m in self.models:
            m.cuda()

    def get_phi_wrapper_class(self):
        return [m.get_phi_wrapper_class() for m in self.models]


class SecmlMalConv(PyTorchModelWrapper):
    def __init__(self, model_config: MalwareModelConfig):
        super().__init__(model_config)
        self.model = MalConv()
        self.model = CClassifierEnd2EndMalware(self.model)
        self.model.load_pretrained_model()
    
    def pre_process_fn(self, X: List[MalwareDatumWrapper]):
        return CArray([End2EndModel.bytes_to_numpy(
            x.bytes, self.model.get_input_max_length(), 256, False
        ) for x in X])
    
    def _forward(self, x):
        retobj = self.model.predict(x, True)
        preds = ch.from_numpy(retobj[1].tondarray()).cuda()
        return preds
    
    def cuda(self):
        # No concept of CUDA for this model
        return
    
    def get_phi_wrapper_class(self):
        return CEnd2EndWrapperPhi


class SecmlGBT(PyTorchModelWrapper):
    def __init__(self, model_config: MalwareModelConfig):
        super().__init__(model_config)
        self.model = CClassifierEmber(tree_path="/p/blackboxsok/datasets/ember_2018_2/ember_model_2018.txt")

    def pre_process_fn(self, X: List[MalwareDatumWrapper]):
         return self.model.extract_features([x.bytes for x in X], direct=True)

    def _forward(self, x):
        retobj = self.model.predict(x, True)
        preds = ch.from_numpy(retobj[1].tondarray()).cuda()
        return preds
    
    def cuda(self):
        # No concept of CUDA for this model
        return
    
    def get_phi_wrapper_class(self):
        return CEmberWrapperPhi


class SecmlSOREL(PyTorchModelWrapper):
    def __init__(self, model_config: MalwareModelConfig):
        super().__init__(model_config)
        self.seeds = [0, 1, 2, 3, 4]
        last_epoch = "epoch_10.pt"
        # model_path = "/p/blackboxsok/models/sorel/FFNN"
        model_path = "/p/blackboxsok/models/sorel/FFNN/seed0/"
        self.model = CClassifierSorel(model_path = os.path.join(model_path, last_epoch), binary_preds=True)

    def pre_process_fn(self, X: List[MalwareDatumWrapper]):
        return CArray([self.model.extract_features(x.bytes, direct=True, wrap=False) for x in X])

    def _forward(self, x):
        retobj = self.model.predict(x, True)
        preds = ch.from_numpy(retobj[1].tondarray()).cuda()
        return preds
    
    def cuda(self):
        self.model._sorel.cuda()

    def get_phi_wrapper_class(self):
        return CSorelWrapperPhi
